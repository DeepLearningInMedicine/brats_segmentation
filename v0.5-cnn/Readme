Author:         Sajid Iqbal (sajidiqbal.pk@gmail.com)
Code Version:   0.5

This file describes the working of toy code for BRATS segmentation challenge.
This code serves following purpose:
1. Reading multimodal medical images
2. Reading the ground truth images
3. preparing medical images for processing
4. applying simple neural network using tensor flow

The version creates a convolutional neural networks that consits of following layers
    1. Input layer:                 input images are divided among 25x25 patches. So input layer contains 625 neurons
    2. First Convolutional layer:   input image of size 625 is reshaped to 25x25 then convolved with 5x5 filter with 32 feature maps
    3. Max pooling layer            2x2 pooling 25x25 image is converted to 13x13
    4. Second convolutional layer:  convolution with 3x3 filter with 32 input feature maps and produces 64 feature maps
    5. Max pooling layer:           2x2 pooling by producing 7x7 output from 13x13
    6. Fully connected layer        converts 64 features maps of size 7x7 into plain layer of 7x7x64
    7. Drop out layer               drops features randomly with specified probability
    8. Output Layer                 applies softmax and produces output of one pass



Segmentation.py
===================================================
    This file creates objects of both classes.
    train_x,train_y,test_x,test_y=br.get_test_n_train_data('BRATS-Training/**/**/**/*.mha') is the only method that needs to be called
    from BRATS class.
    It applies tensorflow classification on patches and gets results.





Prepare_data.py
===================================================
This file defines two classes
    1. BRATS
    2. Training_batch_iterator

BRATS:
    __init__():                 This method defines two variables and initializes them with empty string

    set_training_path(path):    it gets path in glob-package format and from where files are read and next code

    get_training_path():        this method returns training path of data

    set_test_path(path):        this method sets the path of test data set

    get_test_path():            this method returns the path of test set

    read_train_files()          this method reads the training files of different modalities i.e. T1, T1c, T2, Flair and ground truth from BRATS dataset
                                Files of each modality are returned in seperate collection

    make_train_patches(self,data_files_list, label_map_list,patch_size)
                                data_files_list: this is collection of file names belonging to one modality only
                                label_map:       this is collection of ground_truth files
                                patch_size;      size of patches that are required to be made

                                This method gets the data files list and map files list. It reads images from given lists and converts them into numpy array
                                to make processing better, 240x240 matrices are changed to 250x250
                                It creates the patches of same size and class of each file is deduced from the class of central pixel of label map patch
                                the created patches are stored in folder train_patches located in directory where code files are stored

    make_test_patches(self,data_files_list, label_map_list,patch_size):
                                It works in same way as that of make_train_patches for training files.

    make_file_name(self,fname, slice_idx, patch_idx, patch_class):
                                this method makes a name for patch in the format filename-sliceno-patchno-class
                                It is used internally by make-test-patches and make-training-patches

    read_data_n_labels_4m_patches(self,path)
                                this method reads patches from given path and extracts class from file name made in make-file-name method

    make_1hot_encoding(self,pclass):
                                 this method gets patch class as input and creates its one-hot encoding and returns that one-hot encoding

    get_test_n_train_data(self,train_path):
                                this is master method that takes train path and runs all other methods of same class in sequence.
                                It returns train_X,train_Y,test_X,test_Y. No actual data is returned but file names are returned

    read_test_patches(self,test_file_names):
                                test_file_names parameter contains files names in particular patch. It reads data from patch files. Flatens each patch data, creates
                                a matrix and returns it.


Class Training_batch_iterator(object):

    __init__(self):             this is constructor

    get_next_batch(self,X,Y,batch_size):
                                X:          list containing training files names.
                                Y:          list containing label names
                                batch_size: no of patches to be read


Prepare_graph.py
===================================================
This file is important as it defines all the relevant methods required to build graph which is run to find the classificaiton

Class Build_Graph(():
    def __init__(self): class constructor. variable w is taken just to fill constructor. No use of w

    def weight_variable(self,shape):
                 input: shape:          this variable specifies the shape of weight vector i.e. [625,5]
                 output:                randomly initialized weight matrix

    def bias_variable(self,shape):
                 input: shape:          this variable specifies the shape of weight vector i.e. [625,5]
                 output:                randomly initialized weight matrix

    def conv2d(self,x, W):
                                        in this version these methods are defined but not used. we will describe it in next version

    def max_pool_2x2(self,x,ksz,strds):
                 input: x:              the input matrix (image/patch) upon which pooling will be done
                        ksz:            how much matrix to be taken from which max will be taken
                        strds:          strides. how much to move in each direction for next operation. i.e. in our case take maximum
                                        of matrix of size 2x2 as specified by ksize. After taking maximum, move two pixels in particular
                                        direction as specified by strides parameter and then take maximum using ksize.

    def create_input_layer(self,input_size,output_size):
                 input: input_size:     how many input neurons are required. Each neuron correponds to one input. It is input to NN
                        output_size     how many outputs will be produced by neural network
                 output: x:             tf variable describing the input
                         y_:            tf vector defining the output classes

    def create_conv_layer(self,input,new_shape,w_shape,b_shape):
                 input: input:          this is patch/matrix/image to convolutional layer
                        new_shape:      input image is comming in flat/array form that need to be converted to matrix (625 --> 25x25)
                        w_shape:        Specifies the shape of weight vector to convolutional layer
                        b_shape:        specifies the shape of biase vector
                 output  h_conv1:       output matrix of size [_,no.of layer neurons]

    def create_fully_connected_layer(self,input,w_shape,b_shape,flat_shape):
                input: input:          this is patch/matrix/image to convolutional layer
                        new_shape:      input image is comming in flat/array form that need to be converted to matrix (625 --> 25x25)
                        w_shape:        Specifies the shape of weight vector to convolutional layer
                        b_shape:        specifies the shape of biase vector
                        flat_shape:     shape of flattening all input i.e. 13x13x32 in this case
                output  h_conv1:        output matrix of fully connected layer. The output is flat matrix.

    def drop_out(self,input):
                input:  input:          previous layer output is provided as input to this layer.
                output: drop_input      input is applied drop_out method and is returned
                        keep_prob       A parameter that specifies the keep probability

    def create_output_layer(self,input,w_shape,b_shape,actual_output):
                input: input:           input matrix to this layer upon which softmax will be applied
                       w_shape:         shape of weight matrix
                       b_shape:         shape of bias vector
                       actual_output    output layer generated output after applying softmax is compared with actual_output to find out
                                        accuracy of system

